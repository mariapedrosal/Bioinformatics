{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bioinformatics Project\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Cancer classification based on molecular level investigation has gained the interest of researches as it provides a systematic, accurate and objective diagnosis for different cancer types. In this project, we introduce an approach for classifying two different kind of leukaemia based on gene expression profiles. In order to perfom this classification, we applied seven machine learning (ML) algorithms, hoping to get an accurate model that could be used to predict the type of cancer of any patiend based on its expression profile. For this aim, we compared the different classification models basing our conclusions in the AUROC obtained for it. We considered that an AUROC over 0,95 would point to an acceptable model. \n",
    "\n",
    "\n",
    "## Preliminar data analysis\n",
    "\n",
    "Our available data for the performance of prediction models consists in two dataframes. The first one, already labelled as training data, contains 38 observations of patients, to whom the expression of 7129 genes has been assessed in order to identify any characteristic expression pattern for differential diagnosis of two leukaemia conditios: acute myeloid leukaemia (AML) and acute lymphoid leukaemia (ALL). The test data (in which the classification models are going to be tested) consist in the expression levels of the same genes for 34 different pacients. The actual diagnosis of both groups is also provided.\n",
    "\n",
    "## Data pre-processing\n",
    "Due to the vast extension of the data, an initial pre-procesing is needed in order to minimize the number of features to be used with the ML tools.\n",
    "Since the expression levels of many genes has been analysed, it is important to determine which of them show a correlation with the differential diagnosis of the diseases (i.e. which of them show a significant change in the expression when the patient has been diagnosed with ALL or AML).In order to do that, it is useful to perfom a feature selection.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries for the ML analysis\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'C:\\\\Users\\\\Maria\\\\OneDrive\\\\Master\\\\Bioinformatica\\\\Trabajo\\\\Originales\\\\data_set_ALL_AML_train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ed9166db3936>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mruta_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C:\\\\Users\\\\Maria\\\\OneDrive\\\\Master\\\\Bioinformatica\\\\Trabajo\\\\Originales\\\\actual.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mruta_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C:\\\\Users\\\\Maria\\\\OneDrive\\\\Master\\\\Bioinformatica\\\\Trabajo\\\\Originales\\\\data_set_ALL_AML_independent.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mruta_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mruta_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mruta_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\elsa\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\elsa\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\elsa\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\elsa\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\elsa\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'C:\\\\Users\\\\Maria\\\\OneDrive\\\\Master\\\\Bioinformatica\\\\Trabajo\\\\Originales\\\\data_set_ALL_AML_train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "#Reading the files:\n",
    "\n",
    "#These paths might change according to the locations of the files within one's computer\n",
    "ruta_train='C:\\\\Users\\\\Maria\\\\OneDrive\\\\Master\\\\Bioinformatica\\\\Trabajo\\\\Originales\\\\data_set_ALL_AML_train.csv'\n",
    "ruta_y='C:\\\\Users\\\\Maria\\\\OneDrive\\\\Master\\\\Bioinformatica\\\\Trabajo\\\\Originales\\\\actual.csv'\n",
    "ruta_test='C:\\\\Users\\\\Maria\\\\OneDrive\\\\Master\\\\Bioinformatica\\\\Trabajo\\\\Originales\\\\data_set_ALL_AML_independent.csv'\n",
    "train=pd.read_csv(ruta_train)\n",
    "test=pd.read_csv(ruta_test)\n",
    "y=pd.read_csv(ruta_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features are initially placed in the rows of the dataframe, while patients are in the columns. Thus, it is necessary to transpose the data. Besides, there are some columns name 'call', between the patients information, whose data is not relevant for our model. These columns were also removed. Lastly, the name of the features was changed and the actual expression measure was converted into a numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-dcf7150044a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Transposing the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "#Transposing the data\n",
    "train=train.T\n",
    "test=test.T\n",
    "\n",
    "\n",
    "#Removing call data\n",
    "for fila in train.index:\n",
    "    if 'call' in fila:\n",
    "        train=train.drop(fila)\n",
    "\n",
    "for fila in test.index:\n",
    "    if 'call' in fila:\n",
    "        test=test.drop(fila)\n",
    "\n",
    "#Collumns are labelled with the gene accession number\n",
    "\n",
    "columnastrain=train.loc['Gene Accession Number']\n",
    "train=train[2:]\n",
    "train.columns=columnastrain\n",
    "\n",
    "columnastest=test.loc['Gene Accession Number']\n",
    "test=test[2:]\n",
    "test.columns=columnastest\n",
    "\n",
    "#Converting into numeric\n",
    "train=train.astype('float')\n",
    "test=test.astype('float')\n",
    "train.index=train.index.astype(int)\n",
    "test.index=test.index.astype(int)\n",
    "train=train.sort_index()\n",
    "test=test.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response is coded as a categorical variable with 1 coding ALL and 0 coding AML. This response is split into the diagnosis of test and training patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.index=y['patient']\n",
    "y['cancer']=np.where(y.cancer=='ALL', 1, 0) \n",
    "y.groupby('cancer').size() \n",
    "ytrain=y[:len(train)]\n",
    "ytest=y[len(train):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data has the accurate structure, it is time to perform the aforementioned feature selection. Two algorithms for this aim were used in a combined way. In the first one, an univariant selection was performed, and thus each feature was individually selected or removed for the final analysis. In order to do that, the Fischer score was computed and the 100 best atributes were selected. \n",
    "On the other hand, a packing selection tool was used. This type of tools consider the selection as a searching problem (typical of the artificial intelligence tools), and different combinations of features are evaluated and compared. To each of these combinations, a score is computed and assigned and some algorithms are run to select the best combinations. In this case, the algorithm for the selection was the recursive feature removal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected features are: \n",
      "['X71345_f_at', 'L38608_at', 'Z47556_rna2_at', 'U12471_cds1_at', 'K03189_f_at', 'M28585_f_at', 'J03801_f_at', 'U19765_at', 'X67698_at', 'M33317_f_at', 'M63138_at', 'HG4535-HT4940_s_at', 'M27749_r_at', 'X98296_at', 'X72475_at', 'J04027_at', 'Z14978_at', 'X06985_at', 'U82279_at', 'M95178_at', 'HG4490-HT4876_f_at', 'Z83336_at', 'U25975_at', 'L08246_at', 'U61836_at', 'M11147_at', 'M27318_f_at', 'M21551_rna1_at', 'Z80781_at', 'L05188_f_at', 'M62762_at', 'L42583_f_at', 'M92269_f_at', 'L42611_f_at', 'Y00339_s_at', 'M32304_s_at', 'U10690_f_at', 'HG458-HT458_f_at', 'U41767_s_at', 'Z68274_at', 'V00551_f_at', 'L42379_at', 'AFFX-HUMTFRR/M11507_M_at', 'U07132_at', 'Y00787_s_at', 'U84388_at', 'X85116_rna1_s_at', 'X69654_at', 'X60487_at', 'Z48501_s_at', 'U28015_at', 'M81933_at', 'X05345_at', 'Z32765_at', 'X58399_at', 'X06825_at', 'M95678_at', 'D10495_at', 'Z00010_at', 'M20030_f_at', 'HG4236-HT4506_f_at', 'U83117_at', 'X00540_at', 'D14874_at', 'HG67-HT67_f_at', 'Z80779_at', 'U21556_at', 'M81695_s_at', 'X14008_rna1_f_at', 'M68891_at', 'J00148_cds2_f_at', 'X01703_at', 'U82759_at', 'X17042_at', 'M23197_at', 'Z80787_at', 'U82979_at', 'X14767_at', 'U28014_at', 'M90356_f_at', 'M75715_s_at', 'Y13618_at', 'X04085_rna1_at', 'M19045_f_at', 'L08177_at', 'M21904_at', 'M19507_at', 'HG2255-HT2344_f_at', 'HG627-HT5097_s_at', 'U67963_at', 'HG4321-HT4591_at', 'M55150_at', 'X00088_at', 'M77481_rna1_f_at', 'D38128_at', 'K02405_f_at', 'M57423_f_at', 'M83652_s_at', 'M27749_at', 'K03183_f_at', 'U66061_cds3_at', 'D17427_at', 'M22324_at', 'M28130_rna1_s_at', 'L18920_f_at', 'U21689_at', 'Z30643_at', 'D43682_s_at', 'X62654_rna1_at', 'U46751_at', 'L18877_f_at', 'X64364_at', 'M98399_s_at', 'X07496_at', 'J00314_at', 'X75042_at', 'U76388_at', 'X52056_at', 'X13930_f_at', 'U40279_at', 'L00389_f_at', 'D49950_at', 'AJ000480_at', 'Z30644_at', 'X61587_at', 'K03204_f_at', 'L76568_xpt3_f_at', 'M83667_rna1_s_at', 'HG1879-HT1919_at', 'J03071_cds3_f_at', 'L13943_at', 'U66077_at', 'M57710_at', 'X52142_at', 'HG3707-HT3922_f_at', 'HG2917-HT3061_f_at', 'X00090_f_at', 'U03735_f_at', 'X64072_s_at', 'K03207_f_at', 'HG2139-HT2208_f_at', 'X70297_at', 'HG2981-HT3127_s_at', 'U22376_cds2_s_at', 'U65918_f_at', 'M37755_f_at', 'X58431_rna2_s_at', 'M96326_rna1_at', 'M22960_at', 'X07743_at', 'X67491_f_at', 'X89101_s_at', 'HG3527-HT3721_f_at', 'X69115_at', 'X15414_at', 'J00209_f_at', 'X53065_f_at', 'M37435_at', 'X96754_at', 'M16038_at', 'M84526_at', 'M80254_at', 'D86096_cds6_at', 'HG3494-HT3688_at', 'L13278_at', 'L42601_f_at', 'Y00477_at', 'M83221_at', 'M27891_at', 'U50136_rna1_at', 'J00117_f_at', 'L19779_at', 'S82185_at', 'U10689_f_at', 'M69043_at', 'M86406_at', 'M28209_at', 'D26308_at', 'X98225_at', 'V00542_f_at', 'X16546_at', 'L20941_at', 'Y12670_at', 'M31158_at', 'X99133_at', 'HG2915-HT3059_f_at', 'L09209_s_at', 'X95735_at', 'M31211_s_at', 'U22029_f_at', 'X83490_s_at', 'D26156_s_at', 'X07730_at', 'U37055_rna1_s_at', 'HG4027-HT4297_f_at', 'L05144_at', 'X59417_at', 'J00212_f_at']\n"
     ]
    }
   ],
   "source": [
    "#Univariant feature selection (F-score)\n",
    "k = 100  \n",
    "columnas = list(train.columns.values)\n",
    "seleccionadas = SelectKBest(f_classif, k=k).fit(train, ytrain['cancer'])\n",
    "atrib = seleccionadas.get_support()\n",
    "atributos1 = [columnas[i] for i in list(atrib.nonzero()[0])]\n",
    "\n",
    "#Recursive atribute selecion\n",
    "modelo = ExtraTreesClassifier()\n",
    "era = RFE(modelo, 100)  # número de atributos a seleccionar\n",
    "era = era.fit(train, ytrain['cancer'])\n",
    "atrib2 = era.support_\n",
    "atributos2 = [columnas[i] for i in list(atrib2.nonzero()[0])]\n",
    "\n",
    "#Se combinan los tributos elegidos en una lista\n",
    "print('The selected features are: ')\n",
    "atribselec=list(set(atributos1)|set(atributos2))\n",
    "print(atribselec)\n",
    "\n",
    "trainred=pd.DataFrame()\n",
    "for i in atribselec:\n",
    "    trainred[i]=train[i]\n",
    "\n",
    "testred=pd.DataFrame()\n",
    "for i in atribselec:\n",
    "    testred[i]=test[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 100 features have been selected with each type of tool, a maximum number of 200 were considered to be significant for our classification models. They may also be too many, and so a principal component analysis (PCA) was performed. This is a statistical tool used for describing complex data in terms of new uncorrelationated variables. In this case, the algorithm is computed in a way that the new variables maintain the 95% of the variance in the original variables. Since PCA is affected by the data scale, it is necessary to standardize it previously to the computing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "              0             1             2             3             4   \\\n",
      "0   -9719.946506   1897.733260  -5468.825853   -421.292636  -1670.279297   \n",
      "1    3603.085601  -6334.906277  -1478.006496    -30.331072   2567.422317   \n",
      "2   -9537.200508   -271.380681    156.073326  -2195.337254  -2217.662520   \n",
      "3   -9588.668311   -218.602568  -1641.461557  -1002.840966  -1168.085611   \n",
      "4   -6717.558950   -655.595651   4759.141317  -1953.901653   3077.684813   \n",
      "5   -9190.667777  -1522.704311   3131.723675  -3645.631561  -1593.100699   \n",
      "6  -10277.453758   1917.860279    142.098627    368.724046   -823.685989   \n",
      "7   -9443.945005     38.600113  -2316.092980  -1155.947159  -3300.690522   \n",
      "8   -6357.738546   -217.718441  -4765.634738  -2423.467060  -5273.865116   \n",
      "9  -10162.905881   -669.496816   3735.176109    397.963521   2757.394146   \n",
      "10 -10337.789365  -2814.295249   1476.317759   -580.946699   -233.664550   \n",
      "11   1358.090902     28.007157    104.748090   4414.805601     -7.545819   \n",
      "12  -9254.983446  -1556.541590  -5065.088579  -1814.960359   6469.181579   \n",
      "13  -4693.405922  -1131.326631   -639.133592  -3555.724195  -4132.156397   \n",
      "14  -6644.000505   -324.503521  -9873.568801  -3006.057777   1234.462005   \n",
      "15 -12921.742905    -94.890356   3451.805531   -709.450774   1654.738476   \n",
      "16  -3867.277611   2866.815311  -7648.322518   -283.561968  -7170.451379   \n",
      "17  -9685.752337  -2180.950299   1113.381734   -862.120851    998.068646   \n",
      "18 -13170.924953  -2214.354839   3351.007696  -1488.962331   5054.257397   \n",
      "19  -3668.444406  -2699.658567 -11462.704985  -1451.601020   5614.523300   \n",
      "20 -14115.415964   1103.158817    924.484639    963.282418   -126.745625   \n",
      "21 -10971.306246  -3045.580127   4141.166771   1835.829468   5701.363160   \n",
      "22 -13044.155208     28.036165   3969.988428   -897.999977  -2192.991252   \n",
      "23  -9369.690078   4568.545398  -4731.804810   2292.125322  -5266.465194   \n",
      "24   2868.932118  -4953.136242  -1586.623165   8430.973647   4116.556832   \n",
      "25 -10249.344204   1219.197256  -3261.957663    736.173619   3419.683510   \n",
      "26 -13294.514066  -1816.552274   5761.779657  -1642.017739    995.434693   \n",
      "27  16495.570687  -7678.131826  -6362.657921   8770.673005  -3759.947865   \n",
      "28   8201.880445  17605.468856   2163.748093   1753.086593  -1203.056602   \n",
      "29  29661.424725  11085.036649  -1933.250963  -1276.042265  12650.246493   \n",
      "30   7941.662670   6453.311721  11172.350137  -5284.892848  -2243.141711   \n",
      "31  19945.560547  -2528.761441  -6730.839671  -2895.424262  -4121.653284   \n",
      "32  31711.999756 -13480.074880   6413.878725  -1019.235835  -5779.325642   \n",
      "33  14945.231809  14967.681898   -241.993430   7709.563706  -4953.458953   \n",
      "34  -6468.097566    480.698361  12779.710768  -1432.570792  -2541.213044   \n",
      "35  44488.757940  -2647.909443   -905.766509 -12640.354953   1051.343402   \n",
      "36  38189.459237    136.164048   1694.279632   1273.144441    709.782040   \n",
      "37  13341.273592  -5339.243261   5670.873518  14724.328616   1707.044261   \n",
      "\n",
      "              5            6            7            8            9   \\\n",
      "0    1023.684885 -1038.226150 -1577.904155  2399.716835 -1056.029144   \n",
      "1      43.245032  2443.805106  1009.319800   597.926547  4238.406990   \n",
      "2     795.110377 -1726.821893  2423.638772 -2127.135725 -1280.494879   \n",
      "3     405.055322  1029.535968   746.210080   309.155431   137.694195   \n",
      "4    -619.428876   567.816077   869.112996 -2769.653888  4073.120080   \n",
      "5     725.776649  -550.852536  3434.508574  -680.827125  2177.604879   \n",
      "6    -873.649397  -766.723789   944.720446  -528.112872 -2211.836132   \n",
      "7    2385.863182 -1524.768280 -1170.336053  3174.988567  -855.071003   \n",
      "8    1894.670678   -82.001235  2253.685914 -3711.863347  -635.276350   \n",
      "9   -2276.399633 -2035.700467  3583.166897 -1793.806553  -642.191222   \n",
      "10   -198.309920  -619.731270  2617.832824 -4133.418012  1119.765993   \n",
      "11  -5154.380147  -648.443597  -406.566132  4359.710525  4777.480732   \n",
      "12   -568.682776   894.943588 -4643.140781  -960.027223  -637.042550   \n",
      "13   2595.571030  2693.982972  2222.010481  2352.340145  6433.460193   \n",
      "14   2419.367417  3158.074626 -4484.048386 -1074.643319   655.677556   \n",
      "15  -1150.272853  -334.366924 -1014.875435 -1100.684766 -2744.075139   \n",
      "16   1987.407308  4938.880837  4163.847244  -675.757347  -315.634668   \n",
      "17    256.160403  -648.745358 -1391.077902  4307.949849  3424.666921   \n",
      "18    657.131155 -1399.007103 -2032.834794   240.898818  -979.757127   \n",
      "19   3680.287767  6297.242620 -4251.345117   313.243911 -3359.802800   \n",
      "20  -2909.837306 -6659.122116   -27.192546 -5625.762675 -4017.156844   \n",
      "21   2013.889355 -2902.557073   415.776292  1393.818100   160.098733   \n",
      "22    528.291303 -3714.137910  2111.320587   628.369365   469.863466   \n",
      "23   -720.160917   499.699347  2603.870440 -1774.263311    90.835176   \n",
      "24  -8866.048870 -1322.336948 -2147.346962   975.865952  1110.915237   \n",
      "25   -928.400328 -2144.423528 -2962.482181  2174.658337  -763.118700   \n",
      "26   -603.859515 -3086.116835  1685.178410  2942.101816 -1164.169431   \n",
      "27  -2395.396008 -1154.446177 -2007.254180 -3385.777268  1361.056713   \n",
      "28  10193.109998 -5226.493072 -5483.966192  -374.157306  2561.832498   \n",
      "29   -904.329365  3529.399642  7017.047242 -3051.509841   654.759437   \n",
      "30  -3527.936667  6242.634018 -1195.122315  -323.276186 -1427.428407   \n",
      "31  -3872.403131 -1790.123028  5570.105644  6632.020844 -4573.407677   \n",
      "32   2040.502142  -175.247055 -5445.011816 -4976.831314   400.248538   \n",
      "33  -8537.727903  1704.559792 -3323.766302  -660.474455   314.971252   \n",
      "34  -1214.437602  8718.709805 -4115.164499  2954.536009 -3332.415732   \n",
      "35  -2378.457750 -1449.809659  -710.217182  -334.755289   288.775814   \n",
      "36   4910.706682 -7334.006520   -97.981677  3514.325928 -2114.887585   \n",
      "37   9144.288278  5614.924124  4816.281964   791.110845 -2341.439011   \n",
      "\n",
      "             10           11           12  \n",
      "0   -581.515133  1408.871266 -1188.799820  \n",
      "1   2436.748721 -3162.966727  1084.957618  \n",
      "2  -2202.289957  -695.734505  1588.646813  \n",
      "3  -3198.392628   581.627831   181.866733  \n",
      "4   -248.939545 -2164.822614 -2774.595550  \n",
      "5  -3310.862814   910.324623   974.925417  \n",
      "6  -3014.856768  1526.165924  2097.421267  \n",
      "7    385.079095   267.291467   523.666603  \n",
      "8   1771.593099 -2670.375026  1961.134620  \n",
      "9    136.874901 -2846.158629 -1260.117289  \n",
      "10  -606.215958  -907.828473  1070.261184  \n",
      "11  2060.403282 -3135.091027    15.244568  \n",
      "12 -1536.727752   407.297577   430.494897  \n",
      "13  -789.434540   -88.981346  -609.739130  \n",
      "14 -1947.345864  1565.898977   313.633250  \n",
      "15 -1310.695724  -135.419472 -1073.434928  \n",
      "16  2047.416694   659.652786 -1225.998986  \n",
      "17  2630.890321  1104.940886   -88.051504  \n",
      "18 -1461.482616   887.965615    26.129032  \n",
      "19   394.523621 -4710.849185   189.806592  \n",
      "20  6278.460811 -1384.617872  -147.238405  \n",
      "21  2621.593225  3257.562254    17.677161  \n",
      "22  -807.883030  1588.148668  -200.862069  \n",
      "23 -1955.489715  1160.087960  -477.240218  \n",
      "24  -314.451740  -825.196761  3507.560563  \n",
      "25   302.124144  1341.485562 -1386.837262  \n",
      "26 -1860.214558   299.432076 -1179.712501  \n",
      "27  1515.148650  6561.925802  -767.119124  \n",
      "28  3674.389603  -249.291144   685.287326  \n",
      "29   291.386590  2041.307827 -3334.375785  \n",
      "30  1823.549133  -320.811387  4541.613111  \n",
      "31  3248.442111 -1081.091242 -2062.764776  \n",
      "32  -712.481322 -2039.242432 -3980.251745  \n",
      "33 -3551.721051 -1722.901488  -809.034406  \n",
      "34  1569.824290  2000.685654 -2939.049336  \n",
      "35   907.156757  3061.504085  3718.686152  \n",
      "36 -4887.801473 -2803.500306  -188.802595  \n",
      "37   203.197140   312.702797  2765.012523  \n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "TEST\n",
      "              0             1             2             3             4   \\\n",
      "0   -5493.331970   3094.054070  -2062.112132   6944.402151   9187.616284   \n",
      "1  -12208.428496    158.041845   -357.150451  -2134.464559   -267.501784   \n",
      "2  -11802.185917   2757.339266   -620.274010    504.027293  -2894.291046   \n",
      "3    -456.731193  -3732.644854     86.852889    815.887015   6313.623435   \n",
      "4   -5684.095596   2814.592559   2677.444587    193.926633  -1705.490293   \n",
      "5  -11663.617989    447.502627  -1524.566940   -772.893528   2319.018987   \n",
      "6   -4048.406613   7456.537085  -7148.439656   7807.213934   2995.444560   \n",
      "7   -6613.130232   4171.409047  -6484.544866   4227.278669   2068.319616   \n",
      "8  -10528.852303   -950.810811   2414.969261   -780.047620   5280.811494   \n",
      "9   -7117.164112  -1293.484454  -5341.046130   -447.782822   4875.076876   \n",
      "10 -10683.457768   -877.387074   3018.754949  -1587.549638   2329.144864   \n",
      "11  29331.815883   7046.846904  -1970.483680   1853.038028    406.061133   \n",
      "12  24213.499401   6596.581262   5873.693875  11627.411933  -6196.581541   \n",
      "13  19626.484295   3771.316715   6072.844333 -15432.298369   3820.843161   \n",
      "14  25317.204886  13478.621095   8369.762662  -5708.289437   4967.368422   \n",
      "15  -1256.663118  16901.527826  13452.240649  -5085.339049  -3562.813286   \n",
      "16  -9565.934400  -1530.113308   7363.571580  -3963.997185   1376.701126   \n",
      "17 -11467.899442  -1751.183266   5102.398317  -1763.072259   3082.821039   \n",
      "18   2395.263848  23908.723350  10209.152704   -314.061322  -4238.550531   \n",
      "19  11035.626333    333.833896  13576.060922 -12108.407362    459.082492   \n",
      "20  -7751.577766   -498.513138   1250.680205  -5973.204026   7813.206102   \n",
      "21   -839.861640  18658.592608  21588.230740  -1254.751111  -6203.908277   \n",
      "22  10918.527747    -99.874737  10765.474419  11772.893384   -747.609507   \n",
      "23  19497.513884   1449.901835   8584.353648 -17483.021809   4719.364422   \n",
      "24  24483.299678    117.208645   2622.763828 -10328.146317  -1408.274749   \n",
      "25   -732.946115   9409.131416   1970.737937   -370.386236   -495.244672   \n",
      "26  14464.714467   2777.567214   5341.797013   4016.638325   -544.183781   \n",
      "27  -7525.248899   -625.317976   2068.719024     30.859086    673.853487   \n",
      "28   5681.536589  -8502.017386  -5928.140162  -2755.812760  10339.403233   \n",
      "29  -4300.821813    156.677839  -4162.157657   -678.106740   4774.466914   \n",
      "30  -3136.516317  -1534.737379  -9535.249712  -1918.133559   3189.947184   \n",
      "31  -5840.896405   3383.512336   -315.826241   4076.840978   -286.131437   \n",
      "32  -1831.320901  -1753.867449  -8170.600697    260.207891   1850.192546   \n",
      "33  -7157.826815   -262.098572  -3388.241599   1601.914685   2857.898279   \n",
      "\n",
      "             5             6             7            8            9   \\\n",
      "0  -8706.226694  -1469.322673   -140.864141  3804.852590 -3370.982934   \n",
      "1   -603.729354  -1131.766344  -2703.233638  2493.819095   967.524652   \n",
      "2  -1011.670558  -3638.388186    214.376584   251.071042  -347.823783   \n",
      "3   2215.012360   1649.507207  -4370.594893  2111.476948 -2309.179072   \n",
      "4   4694.219731  -3277.779251  -3140.272062  2015.655380  -127.532903   \n",
      "5   -569.527296  -3851.856957  -2591.513436  2388.528546 -1925.227717   \n",
      "6  -6355.782230  -1734.099917   1842.139981  4766.438097  -431.398111   \n",
      "7  -3245.609126  -1717.395541  -1362.278522  5970.818096  -579.603877   \n",
      "8    263.476995   -975.495880  -2778.281757  2175.632938    -3.253082   \n",
      "9      6.536438   2843.368466  -1303.327136 -2978.200932 -1581.239940   \n",
      "10 -3605.199617  -2414.094296  -1143.286747  1203.594831 -4556.634580   \n",
      "11 -4545.945133   2858.799767  -4100.022510  1939.551885 -2150.541555   \n",
      "12 -4280.052887  -5379.806291  -9534.355495 -1531.955516 -2092.256970   \n",
      "13  5877.736106  -4019.728848   7209.840709  7176.885602  1188.882156   \n",
      "14  4867.459222   1991.224292   2537.419195  2326.024354 -2505.726620   \n",
      "15  2677.398172   4621.640303  -9312.760040  -251.690569 -8061.609868   \n",
      "16   179.209570  -1772.893870  -1285.167781  2374.508756  1850.771787   \n",
      "17  -305.963241  -2161.700298   -994.911179  3830.662927   699.682444   \n",
      "18  6374.611732   -410.533335 -10480.268507   835.027527  4295.663477   \n",
      "19  1033.412108   4719.125543  -1398.275108  9109.570662 -1704.343561   \n",
      "20    -9.710702    113.465228  -7997.324065  3584.873810  -917.339350   \n",
      "21  3934.510445   8014.915341 -16635.643760 -2108.893617 -1065.955600   \n",
      "22 -9141.075624  12608.380119  -8240.549953  5158.727383 -9450.369180   \n",
      "23  3369.891692   2916.179744   7719.528476  9173.857951  2512.016561   \n",
      "24 -3085.952044   2232.664109   3190.693118  1626.665706 -2054.563117   \n",
      "25 -2829.510486   4097.579370  -1288.549758  1548.976257 -5850.494648   \n",
      "26 -2685.175828   6562.644413  -3107.820577  4312.032040 -2994.697554   \n",
      "27  1130.852380  -1552.222036   -326.872427  1854.202769  1808.990088   \n",
      "28  3170.357333   1550.794514  -7518.188015   793.909557  2938.475601   \n",
      "29 -1667.670767   1897.277588   -981.825646 -3653.565502 -2279.962744   \n",
      "30  1157.322484   3914.326155  -4091.212542 -1035.396647   465.613104   \n",
      "31 -8672.796637  -3009.662186    977.083930  2460.778148 -1121.449751   \n",
      "32 -6833.849467   -851.721931  -7309.565652  2855.506702  1360.504743   \n",
      "33 -1867.965539   -885.444301  -1721.621891   903.979650   181.530999   \n",
      "\n",
      "              10           11           12  \n",
      "0   -3558.965745 -3401.220212   471.744824  \n",
      "1   -1513.274867  3143.159992  -695.730484  \n",
      "2     953.479092   604.147277    72.126358  \n",
      "3    -627.158532 -1589.147842  4353.646445  \n",
      "4    1518.172295 -2488.746380  -688.145659  \n",
      "5    1909.545228  -888.828236   705.990065  \n",
      "6    -325.059098 -3623.346367 -1614.004290  \n",
      "7     887.854781 -1963.940346   356.159687  \n",
      "8     736.076013   327.857640  -503.186464  \n",
      "9   -1617.319141 -1802.841828  1731.085737  \n",
      "10  -2441.399584   157.362114   949.500325  \n",
      "11    631.722730  1103.626203  -392.838701  \n",
      "12  -3324.282790   471.419758 -1999.223861  \n",
      "13  11376.864870 -6703.451925  -149.651415  \n",
      "14   3072.613815  -855.247742 -1267.690926  \n",
      "15   5026.609244  4463.782565 -4727.694585  \n",
      "16   -799.319338  -703.163474  -863.364771  \n",
      "17   -197.767867  1388.361540  -425.035058  \n",
      "18   6412.991535 -2522.833481  2544.194087  \n",
      "19   5163.578290 -4966.345853  -851.864990  \n",
      "20  -2509.323309 -2296.404771 -1256.283355  \n",
      "21   5280.518201 -1069.763830 -2109.003017  \n",
      "22   2835.905622 -7449.323216 -8325.220635  \n",
      "23  11705.346725 -3953.790320  2629.066784  \n",
      "24   9046.187911  3972.234338  4300.169562  \n",
      "25   -727.073237  4609.457504 -2981.269922  \n",
      "26  12158.941403  -827.905818  -328.839761  \n",
      "27   2580.085800  2760.689518  1468.885907  \n",
      "28   5236.994278  1766.271006  -493.302691  \n",
      "29   -793.297568 -2094.943066   167.031144  \n",
      "30   1416.578544   309.793186   660.024722  \n",
      "31   -174.385856 -1567.839631  2294.739482  \n",
      "32   2064.207665  4144.585145  3159.494172  \n",
      "33   3773.283952    30.927786  -309.143395  \n"
     ]
    }
   ],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(trainred)\n",
    "train=scaler.transform(trainred)\n",
    "test=scaler.transform(testred)\n",
    "\n",
    "pca=PCA(.95) \n",
    "pca.fit(trainred)\n",
    "\n",
    "train=pca.transform(trainred)\n",
    "test=pca.transform(testred)\n",
    "\n",
    "print(\"TRAIN\")\n",
    "print(pd.DataFrame(train))\n",
    "print(\"\\n\"+\"-\"*50+\"\\n\")\n",
    "print(\"TEST\")\n",
    "print(pd.DataFrame(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning algorithms to compute classifiers\n",
    "\n",
    "Up to this point, we are now able to perform the machine learnings algorithms in order to establish a classification model for the leukaemia diagnosis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear discriminant analysis\n",
    "\n",
    "This model is a generalization of Fisher's linear discriminant and it is used in machine learning to find a linear combination of features that characterizes or separates two or more classes of objects or events. The resulting is used as a linear classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSSION MATRIX\n",
      "\n",
      "TEST\n",
      "\n",
      "Predicted diagnosis   0   1\n",
      "Actual diagnosis           \n",
      "0                    13   1\n",
      "1                     0  20\n",
      "\n",
      "TRAIN\n",
      "\n",
      "Predicted diagnosis   0   1\n",
      "Actual diagnosis           \n",
      "0                    11   0\n",
      "1                     0  27\n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       0.95      1.00      0.98        20\n",
      "\n",
      "avg / total       0.97      0.97      0.97        34\n",
      "\n",
      "\n",
      "AUROC\n",
      "\n",
      "0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()  # Creating the Linear Discriminant Analysis\n",
    "lda.fit(train, ytrain['cancer']) # Fitting the model\n",
    "ypred_t_lda=lda.predict(train)\n",
    "ypred_lda=lda.predict(test)\n",
    "\n",
    "print(\"CONFUSSION MATRIX\")\n",
    "print(\"\\nTRAIN\\n\")\n",
    "print(pd.crosstab(ytrain['cancer'],ypred_t_lda, rownames=['Actual diagnosis'], colnames=['Predicted diagnosis']))\n",
    "print(\"\\nTEST\\n\")\n",
    "print(pd.crosstab(ytest['cancer'],ypred_lda, rownames=['Actual diagnosis'], colnames=['Predicted diagnosis']))\n",
    "\n",
    "print(\"\\nCLASSIFICATION REPORT\\n\")\n",
    "print(classification_report(ytest['cancer'], ypred_lda))\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(ytest['cancer'], ypred_lda)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"\\nAUROC\\n\")\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model\n",
    "\n",
    "Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes’ theorem with the “naive” assumption \n",
    "of conditional independence between every pair of features given the value of the class variable. In this case, we have implemented the\n",
    "Gaussian Naive Bayes classifier, which is a special type or Naive Bayes algorithm. It’s specifically used when the features have continuous values.\n",
    "Then, the algorithm creates a classification report that contains the various statistics required to judge a model and a confusion matrix  which will give us a clear idea of the accuracy and the fitting of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN\n",
      "\n",
      "\tCONFUSION MATRIX\n",
      "Predicted diagnosis   0   1\n",
      "Expected diagnosis         \n",
      "0                    11   0\n",
      "1                     1  26\n",
      "\n",
      "\tACCURACY\n",
      "0.9736842105263158\n",
      "\n",
      "\n",
      "TEST\n",
      "\n",
      "\tCLASSIFICATION REPORT\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.93      0.84        14\n",
      "          1       0.94      0.80      0.86        20\n",
      "\n",
      "avg / total       0.87      0.85      0.85        34\n",
      "\n",
      "\n",
      "\tCONFUSION MATRIX\n",
      "Predicted diagnosis   0   1\n",
      "Expected diagnosis         \n",
      "0                    13   1\n",
      "1                     4  16\n",
      "\n",
      "\tACCURACY\n",
      "0.8529411764705882\n",
      "\n",
      "AUROC\n",
      "\n",
      "0.8642857142857143\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB() # Creating the Naive Bayes model\n",
    "model.fit(train, ytrain['cancer']) # Fitting the model\n",
    "\n",
    "expected = ytrain['cancer']\n",
    "ypred_t_by = model.predict(train)  # Making predictions(train)\n",
    "\n",
    "# Getting Accuracy and Statistics (train)\n",
    "print('\\nTRAIN\\n\\n\\tCONFUSION MATRIX')\n",
    "print(pd.crosstab(expected,ypred_t_by, rownames=['Expected diagnosis'], colnames=['Predicted diagnosis']))\n",
    "print('\\n\\tACCURACY')\n",
    "print(accuracy_score(expected, ypred_t_by, normalize = True))\n",
    "\n",
    "expected = ytest['cancer']\n",
    "ypred_by = model.predict(test)  # Making predictions(test)\n",
    "\n",
    "# Getting Accuracy and Statistics (test)\n",
    "print('\\n\\nTEST\\n\\n\\tCLASSIFICATION REPORT')\n",
    "print(metrics.classification_report(expected, ypred_by))\n",
    "print('\\n\\tCONFUSION MATRIX')\n",
    "print(pd.crosstab(expected,ypred_by, rownames=['Expected diagnosis'], colnames=['Predicted diagnosis']))\n",
    "print('\\n\\tACCURACY')\n",
    "print(accuracy_score(expected, ypred_by, normalize = True))\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(ytest['cancer'], ypred_by)\n",
    "roc_auc_by = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"\\nAUROC\\n\")\n",
    "print(roc_auc_by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is fits properly to the training data. As it can be seen in the confusion matrix, the prediction was correct in 37 out of 38 patients. However, at the time of making the prediction with the test data, the model manages to make fewer correct predictions, since it only adequately diagnoses 30 of 34 patients. Even so, our model is quite accurate classifying the categories of our dataset.\n",
    "\n",
    "### Decision tree\n",
    "\n",
    "The second implemented algorithm was the decision tree classifier, which computes a diagram with logic construction in order to represent a set of conditions, which are consecutively assessed for the resolution of a problem. In order to get the best results, the parameters to be used for building the model where calculated using a cross-validation algorithm. The best parameters were used to build the final decision tree, which was evaluated with the test sample, constructing the confussion matrix. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n",
      "{'min_samples_split': 2, 'max_depth': 2}\n",
      "CONFUSSION MATRIX\n",
      "\n",
      "TRAIN\n",
      "\n",
      "Predicted diagnosis   0   1\n",
      "Actual diagnosis           \n",
      "0                    11   0\n",
      "1                     0  27\n",
      "\n",
      "TEST\n",
      "\n",
      "Predicted diagnosis   0   1\n",
      "Actual diagnosis           \n",
      "0                    12   2\n",
      "1                     0  20\n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92        14\n",
      "          1       0.91      1.00      0.95        20\n",
      "\n",
      "avg / total       0.95      0.94      0.94        34\n",
      "\n",
      "\n",
      "AUROC\n",
      "\n",
      "0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "split_range=list(range(2,15))\n",
    "prof_range=list(range(2, 10))\n",
    "\n",
    "param_grid={'min_samples_split':split_range, 'max_depth':prof_range}\n",
    "clf_gini = DecisionTreeClassifier(criterion = 'gini', random_state=100)\n",
    "grid_dt=GridSearchCV(clf_gini, param_grid, scoring='accuracy')\n",
    "grid_dt.fit(train, ytrain['cancer'])\n",
    "print(grid_dt.best_score_)\n",
    "print(grid_dt.best_params_)\n",
    "\n",
    "mejor_clf_gini=grid_dt.best_estimator_\n",
    "\n",
    "\n",
    "ypred=mejor_clf_gini.predict(test)\n",
    "ypred_t=mejor_clf_gini.predict(train)\n",
    "\n",
    "print(\"CONFUSSION MATRIX\")\n",
    "print(\"\\nTRAIN\\n\")\n",
    "print(pd.crosstab(ytrain['cancer'],ypred_t, rownames=['Actual diagnosis'], colnames=['Predicted diagnosis']))\n",
    "\n",
    "print(\"\\nTEST\\n\")\n",
    "print(pd.crosstab(ytest['cancer'],ypred, rownames=['Actual diagnosis'], colnames=['Predicted diagnosis']))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nCLASSIFICATION REPORT\\n\")\n",
    "print(classification_report(ytest['cancer'], ypred))\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(ytest['cancer'], ypred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"\\nAUROC\\n\")\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculated decision tree is not a bad classifier, but there is some kind of overfitting. When we apply this model to the training set, the accuracy of it is perfect: every patient is correctly diagnose. However, when running the classifier model for the test set, 3 patients are misdiagnosed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "Instead of using a single decision tree, this algorithm computes a whole forest of trees with little depth. In order to obtain the classification result, it takes the individual result of each tree and the resulting class is the most \"voted\" one. \n",
    "In order to tackle the aforementioned overfitting, a cross-validation search of the best hypeparameters was also performed. \n",
    "Due to the high number of hyperparameters to be tested, two tipes of parameter search are computed. In first place, a random search is perform in order to get close to the actual best value of each parameter. Once we have some idea of this approximate value, we perform the grid search by building a grid within a range including this approximation. Best computed parameters are finally used to compute the final ranfom forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf_clf=RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf_clf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=100, n_jobs = -1)\n",
    "rf_random.fit(train, ytrain['cancer'])\n",
    "\n",
    "\n",
    "\n",
    "print(rf_random.best_params_)\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [None],\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'n_estimators': [500, 1000, 2000]\n",
    "}\n",
    "\n",
    "grid_rf=GridSearchCV(rf_clf, param_grid, scoring='accuracy', cv=3)\n",
    "grid_rf.fit(train, ytrain['cancer'])\n",
    "print(grid_rf.best_score_)\n",
    "print(grid_rf.best_params_)\n",
    "\n",
    "mejor_rf_clf=grid_rf.best_estimator_\n",
    "\n",
    "\n",
    "ypred_rf=mejor_rf_clf.predict(test)\n",
    "\n",
    "print(\"CONFUSSION MATRIX\")\n",
    "print(\"\\nTRAIN\\n\")\n",
    "print(pd.crosstab(ytrain['cancer'],ypred_t_rf, rownames=['Actual diagnosis'], colnames=['Predicted diagnosis']))\n",
    "print(\"\\nTEST\\n\")\n",
    "print(pd.crosstab(ytest['cancer'],ypred_rf, rownames=['Actual diagnosis'], colnames=['Predicted diagnosis']))\n",
    "ypred_t_rf=mejor_rf_clf.predict(train)\n",
    "\n",
    "\n",
    "print(\"\\nCLASSIFICATION REPORT\\n\")\n",
    "print(classification_report(ytest['cancer'], ypred_rf))\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(ytest['cancer'], ypred_rf)\n",
    "roc_auc_rf = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"\\nAUROC\\n\")\n",
    "print(roc_auc_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "This model is a type of supervised machine learning classification algorithm. The algorithm chooses the most optimal decision boundary (a region which maximizes the distance between the nearest data of all the classes), which is the one that has the maximum margin from the nearest points of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSSION MATRIX\n",
      "\n",
      "TEST\n",
      "\n",
      "Predicted diagnosis   0   1\n",
      "Actual diagnosis           \n",
      "0                    13   1\n",
      "1                     0  20\n",
      "\n",
      "TRAIN\n",
      "\n",
      "Predicted diagnosis   0   1\n",
      "Actual diagnosis           \n",
      "0                    11   0\n",
      "1                     0  27\n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       0.95      1.00      0.98        20\n",
      "\n",
      "avg / total       0.97      0.97      0.97        34\n",
      "\n",
      "\n",
      "AUROC\n",
      "\n",
      "0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(train, ytrain['cancer'])\n",
    "ypred_svm = svclassifier.predict(test)\n",
    "ypred_t_svm=svclassifier.predict(train)\n",
    "\n",
    "print(\"CONFUSSION MATRIX\")\n",
    "print(\"\\nTRAIN\\n\")\n",
    "print(pd.crosstab(ytrain['cancer'],ypred_t_svm, rownames=['Actual diagnosis'], colnames=['Predicted diagnosis']))\n",
    "print(\"\\nTEST\\n\")\n",
    "print(pd.crosstab(ytest['cancer'],ypred_svm, rownames=['Actual diagnosis'], colnames=['Predicted diagnosis']))\n",
    "\n",
    "\n",
    "print(\"\\nCLASSIFICATION REPORT\\n\")\n",
    "print(classification_report(ytest['cancer'], ypred_svm))\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(ytest['cancer'], ypred_svm)\n",
    "roc_auc_svm = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"\\nAUROC\\n\")\n",
    "print(roc_auc_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "This model is a type of supervised machine learning classification algorithm which is used to predict the probability of a categorical dependent variable. The model show a threshold in whom will be specified the result of one of the classes. It is important to point that this algorithm follows Bernoulli Distribution and the final results are shown in a confussion matrix, which evaluates the performance of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSSION MATRIX\n",
      "\n",
      "TRAIN\n",
      "\n",
      "Predicted diagnosis   0   1\n",
      "Actual diagnosis           \n",
      "0                    11   0\n",
      "1                     0  27\n",
      "\n",
      "TEST\n",
      "\n",
      "Predicted diagnosis   0   1\n",
      "Actual diagnosis           \n",
      "0                    13   1\n",
      "1                     0  20\n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        14\n",
      "          1       0.95      1.00      0.98        20\n",
      "\n",
      "avg / total       0.97      0.97      0.97        34\n",
      "\n",
      "\n",
      "AUROC\n",
      "\n",
      "0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "rlog = LogisticRegression() # Creando el modelo\n",
    "rlog.fit(train, ytrain['cancer']) \n",
    "ypred_t_rlog = rlog.predict(train) \n",
    "ypred_rlog = rlog.predict(test)\n",
    "\n",
    "print(\"CONFUSSION MATRIX\")\n",
    "print(\"\\nTRAIN\\n\")\n",
    "print(pd.crosstab(ytrain['cancer'],ypred_t_rlog, rownames=['Actual diagnosis'], colnames=['Predicted diagnosis']))\n",
    "print(\"\\nTEST\\n\")\n",
    "print(pd.crosstab(ytest['cancer'],ypred_rlog, rownames=['Actual diagnosis'], colnames=['Predicted diagnosis']))\n",
    "\n",
    "\n",
    "print(\"\\nCLASSIFICATION REPORT\\n\")\n",
    "print(classification_report(ytest['cancer'], ypred_rlog))\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(ytest['cancer'], ypred_rlog)\n",
    "roc_auc_rlog = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"\\nAUROC\\n\")\n",
    "print(roc_auc_rlog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network \n",
    "This classification model is based in the biological neurons. It receives an input and produces a signal (output) based on it which is received by another neuron as a new input. Each neuron has an activation function, which determines whether an output is computed for a determined input will be sended to another neuron or not. Due to the complexity of this algorithm, in this case no parameter search was computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSSION MATRIX\n",
      "\n",
      "TEST\n",
      "\n",
      "Predicted diagnosis   0   1\n",
      "Actual diagnosis           \n",
      "0                    10   4\n",
      "1                     5  15\n",
      "\n",
      "TRAIN\n",
      "\n",
      "Predicted diagnosis  0   1\n",
      "Actual diagnosis          \n",
      "0                    8   3\n",
      "1                    4  23\n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.71      0.69        14\n",
      "          1       0.79      0.75      0.77        20\n",
      "\n",
      "avg / total       0.74      0.74      0.74        34\n",
      "\n",
      "\n",
      "AUROC\n",
      "\n",
      "0.7321428571428571\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))\n",
    "mlp.fit(train, ytrain['cancer'])\n",
    "ypred_nn=mlp.predict(test)\n",
    "\n",
    "print(\"CONFUSSION MATRIX\")\n",
    "print(\"\\nTEST\\n\")\n",
    "print(pd.crosstab(ytest['cancer'],ypred_nn, rownames=['Actual diagnosis'], colnames=['Predicted diagnosis']))\n",
    "ypred_t_nn=mlp.predict(train)\n",
    "print(\"\\nTRAIN\\n\")\n",
    "print(pd.crosstab(ytrain['cancer'],ypred_t_nn, rownames=['Actual diagnosis'], colnames=['Predicted diagnosis']))\n",
    "\n",
    "print(\"\\nCLASSIFICATION REPORT\\n\")\n",
    "print(classification_report(ytest['cancer'], ypred_nn))\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(ytest['cancer'], ypred_nn)\n",
    "roc_auc_nn = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"\\nAUROC\\n\")\n",
    "print(roc_auc_nn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion and conclusion\n",
    "Using different machine learning (ML) tools, we have been able to obtain some models tha could certainly be useful when differentially diagnosis these two types of canceer. The best results have been achieved when Linear Discriminant Analysis, Support Vector Machine and Logistic Regression models were used, with whom default parameters were set. This lead us to the conclusion that sometimes the easiest approach is also the most convinient.\n",
    "On the other hand, poor results were got when a neural netwok model was used. This could be due to the high complexity of this kind of models, in which many parameters can be set in order to get to the best results. \n",
    "Finally, best parameter search was performed in decision tree and random forest, just in order to get to know the tools commonly used for this aim. We found that this is a useful but time-consuming and computer demanding technique.\n",
    "On the whole, we have proved that ML analysis consist in an interesting tool with a vast range of application in precission medicine. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
